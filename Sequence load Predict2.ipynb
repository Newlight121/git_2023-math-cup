{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 26.0\n",
      "2 23.0\n",
      "3 24.0\n",
      "4 28.0\n",
      "5 43.0\n",
      "6 26.0\n",
      "7 26.0\n",
      "8 31.0\n",
      "10 25.0\n",
      "12 27.0\n",
      "13 35.0\n",
      "14 23.0\n",
      "15 24.0\n",
      "16 23.0\n",
      "17 30.0\n",
      "19 23.0\n",
      "20 25.0\n",
      "21 23.0\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from keras.models import load_model\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         # Currently, memory growth needs to be the same across GPUs\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#\n",
    "#         # Memory growth must be set before GPUs have been initialized\n",
    "#         print(e)\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "table = pd.read_csv(\"/workspace/附件5编码_fianl2.csv\", encoding=\"utf-8\", index_col=False)\n",
    "table_save = table.copy()\n",
    "table[\"data_len\"] = np.nan\n",
    "table_data = table[\"data\"]  # 获取data数据\n",
    "for i in range(len(table)):\n",
    "    table[\"data_len\"].iloc[i] = len(eval(table[\"data\"].iloc[i]))\n",
    "for fenlei_index in range(0, 22):\n",
    "    category_data = table[table['fenlei'] == fenlei_index]\n",
    "    if not category_data.empty:\n",
    "        print(fenlei_index, min(category_data[\"data_len\"]))\n",
    "\n",
    "# 定义滑动窗口的宽度与预测长度\n",
    "window_size = 23\n",
    "# 预测接下来的y_pre_len个时间点长度\n",
    "next_predict = 30\n",
    "\n",
    "y_pre_len = 5\n",
    "\n",
    "for i in range(next_predict+y_pre_len-1):\n",
    "    table_save[\"extend_data\"+str(i+1)] = np.nan #初始化nan\n",
    "\n",
    "for index, line in enumerate(table_data):\n",
    "    category_class = table['fenlei'].iloc[index]  # 获取类别\n",
    "    category_ylist = line\n",
    "\n",
    "    category_ylist = np.expand_dims(np.array(eval(category_ylist)), axis=0)\n",
    "    model = load_model(\"/workspace/model_save2/\" + \"model_class_\" + str(category_class) + \"_choosen\" + \".h5\")\n",
    "\n",
    "    # 预测未来时间步的值\n",
    "    future_input = category_ylist[:, -window_size:]  # 选取最后数据作为初始预测未来的输入\n",
    "    future_input = future_input.reshape(-1, window_size, 1)\n",
    "    future_predictions = []\n",
    "\n",
    "    for _ in range(next_predict):\n",
    "        future_prediction = model.predict(future_input)\n",
    "        future_predictions.append(future_prediction)\n",
    "        # 更新输入窗口，添加新的预测值，删除第一个时间步的数据\n",
    "        # future_input = np.concatenate((future_input[:, y_pre_len:, :], future_prediction.reshape(-1,y_pre_len,1)), axis=1)\n",
    "        future_input = np.concatenate((future_input[:, 1:, :], np.round(future_prediction[:, 0:1]).reshape(-1, 1, 1)),\n",
    "                                      axis=1)  # 步进1进行输入\n",
    "        # print(future_input[1, -8:-1].reshape(1, -1))\n",
    "\n",
    "    # 将预测结果转换为NumPy数组\n",
    "    future_predictions = np.array(future_predictions).transpose(1, 0, 2).reshape(-1, next_predict, y_pre_len)\n",
    "\n",
    "    # 创建一个长度为 next_predict+y_pre_len 的数组来存储输出\n",
    "    final_output = np.zeros((future_predictions.shape[0], next_predict + y_pre_len - 1))\n",
    "    weights = np.zeros(next_predict + y_pre_len - 1)\n",
    "\n",
    "    # 对预测结果进行滑动窗口整合\n",
    "    for i in range(future_predictions.shape[1]):\n",
    "        final_output[:, i:i + 5] += future_predictions[:, i]\n",
    "        weights[i:i + 5] += 1\n",
    "\n",
    "    # 计算最终输出的平均值\n",
    "    final_output = final_output / weights\n",
    "    future_predictions = final_output.reshape(-1, next_predict + y_pre_len - 1, 1)\n",
    "\n",
    "    future_predictions = np.round(future_predictions)\n",
    "\n",
    "    for i in range(future_predictions.shape[1]):\n",
    "        table_save[\"extend_data\" + str(i + 1)].loc[category_data.index] = future_predictions[:, i].flatten()\n",
    "\n",
    "    select_index = 0\n",
    "    plot_series_data = category_ylist[select_index]\n",
    "    plot_future_prediction = future_predictions[select_index]\n",
    "    # 绘制时间序列数据和预测值，使用不同颜色区分\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(np.arange(len(plot_series_data)), plot_series_data, label='Original Data', color='blue')\n",
    "    plt.plot(np.arange(len(plot_series_data) - 1, len(plot_series_data) + next_predict + y_pre_len - 1),\n",
    "             np.insert(plot_future_prediction, 0, plot_series_data[-1]),\n",
    "             label='Predicted Data', color='green', ls=\"--\")\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"save_pic1/\" + str(select_index) + str(fenlei_index) + \".svg\")\n",
    "    plt.show()\n",
    "\n",
    "    table_save.to_csv(\"/workspace/table_save3/table_save_\"+str(fenlei_index)+\"_.csv\")\n",
    "pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
