{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from re import T\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from keras.models import load_model\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "table_review = pd.read_csv(\"/workspace/1111.csv\", encoding=\"gb18030\", index_col=0)\n",
    "\n",
    "table = pd.read_csv(\"/workspace/q1_result.csv\", encoding=\"utf-8\", index_col=0)\n",
    "\n",
    "merged_table = pd.merge(pd.concat([table.loc[:,['seller', 'product', 'house',\"fenlei2\"]],table.loc[:,'2022/12/1':'2023/5/30']],axis=1) ,table_review.loc[:,['seller', 'product', 'house','data']],  on=['seller', 'product', 'house',])\n",
    "table_save = merged_table.copy()\n",
    "\n",
    "for i in range(11):\n",
    "    table_save[\"extend_data\" + str(i)] = np.nan  # 初始化nan\n",
    "\n",
    "for i,line in enumerate(merged_table[\"data\"]):\n",
    "    line = eval(line)\n",
    "    for j in range(len(line)):\n",
    "        table_save.loc[i,\"extend_data\" + str(10-j)] = line[-(j+1)]\n",
    "\n",
    "table_save_data = table_save[\"data\"]\n",
    "table_save = table_save.drop(\"data\",axis = 1)\n",
    "\n",
    "table_save = table_save.interpolate(method='linear', axis=0)\n",
    "\n",
    "table_save = pd.concat([table_save, table_save_data],axis=1)\n",
    "table_save.to_csv(\"extend.csv\") #保存插值扩展后的结果\n",
    "\n",
    "table_save = table_save.drop(\"data\",axis = 1)\n",
    "\n",
    "\n",
    "table = table_save.copy()\n",
    "table_save = table.copy()\n",
    "\n",
    "# 定义滑动窗口的宽度与预测长度\n",
    "window_size = 30\n",
    "# 预测接下来的y_pre_len个时间点长度\n",
    "next_predict = 16\n",
    "y_pre_len = 5\n",
    "\n",
    "for i in range(next_predict+y_pre_len-1):\n",
    "    table_save[\"extend_extend_data\"+str(i+1)] = np.nan #初始化nan\n",
    "\n",
    "for fenlei_index in range(0,22):\n",
    "    fenlei = fenlei_index\n",
    "    category_data = table[table['fenlei2'] == fenlei]\n",
    "    start_index = 155\n",
    "    len_index = 41\n",
    "    category_t = category_data.columns[start_index:start_index+len_index]\n",
    "    # datetime_list = [datetime.timestamp(datetime.strptime(ts, '%Y/%m/%d')) for ts in category_t]\n",
    "\n",
    "    category_ylist = category_data.iloc[:, start_index:start_index+len_index]\n",
    "\n",
    "    time_series_data = np.array(category_ylist)\n",
    "\n",
    "        # 准备数据，将时间序列数据分割成输入（X）和输出（y）\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(time_series_data.shape[1] - window_size - y_pre_len+1):\n",
    "        X.append(time_series_data[:, i:i + window_size])\n",
    "        y.append(time_series_data[:, i + window_size:i + window_size + y_pre_len])\n",
    "\n",
    "    X = np.array(X).transpose(1, 0, 2).reshape(-1, len_index - window_size- y_pre_len+1, window_size, 1)\n",
    "    print(X.shape)\n",
    "    y = np.array(y).transpose(1, 0, 2)\n",
    "\n",
    "    loss_min = 999999999\n",
    "    final_choosen = None\n",
    "\n",
    "    model = load_model(\"/workspace/model_save1/\"+\"model_class_\"+str(fenlei_index)+\"_choosen\" +\".h5\")\n",
    "    # 编译模型\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss=\"mean_squared_error\")\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    loss_tmp = 0\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # 将输入数据形状调整为适合RNN模型的形状\n",
    "        X_train = X_train.reshape(-1, window_size, 1)\n",
    "        X_test = X_test.reshape(-1, window_size, 1)\n",
    "        y_train = y_train.reshape(-1, y_pre_len, 1)\n",
    "        y_test = y_test.reshape(-1, y_pre_len, 1)\n",
    "\n",
    "        X_train, X_test = tf.convert_to_tensor(X_train), tf.convert_to_tensor(X_test)\n",
    "        y_train, y_test = tf.convert_to_tensor(y_train), tf.convert_to_tensor(y_test)\n",
    "        # 训练模型并添加动态进度条显示\n",
    "        epochs = 20\n",
    "        batch_size = 32  # 训练模型\n",
    "        for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "            model.fit(X_train, y_train, epochs=1, batch_size=batch_size, verbose=0, workers=8)\n",
    "        \n",
    "        # 在测试集上进行预测\n",
    "        test_loss = model.evaluate(X_test, y_test)\n",
    "        train_loss = model.evaluate(X_train, y_train)\n",
    "        print(\"Train loss:\", train_loss)\n",
    "        print(\"Test loss:\", test_loss)\n",
    "        \n",
    "        loss_tmp = loss_tmp + test_loss + train_loss\n",
    "\n",
    "\n",
    "    # 预测历史时间步的值\n",
    "    history_input = X\n",
    "    history_input = history_input.reshape(-1, window_size, 1)\n",
    "    history_predictions = []\n",
    "    history_prediction = model.predict(history_input)\n",
    "    history_predictions.append(history_prediction)\n",
    "\n",
    "    history_predictions = np.array(history_predictions).reshape(-1, len_index - window_size - y_pre_len + 1, y_pre_len)[:,\n",
    "                            :, -1]\n",
    "\n",
    "\n",
    "    # 预测未来时间步的值\n",
    "    # future_input = X[:, -1:]  # 使用最后一个窗口的数据作为输入\n",
    "    future_input = time_series_data[:, -window_size:]  # 选取最后数据作为初始预测未来的输入\n",
    "    future_input = future_input.reshape(-1, window_size, 1)\n",
    "    future_predictions = []\n",
    "    for _ in range(next_predict):\n",
    "        future_prediction = model.predict(future_input)\n",
    "        future_predictions.append(future_prediction)\n",
    "        # 更新输入窗口，添加新的预测值，删除第一个时间步的数据\n",
    "        # future_input = np.concatenate((future_input[:, y_pre_len:, :], future_prediction.reshape(-1,y_pre_len,1)), axis=1)\n",
    "        future_input = np.concatenate((future_input[:, 1:, :], np.round(future_prediction[:,0:1]).reshape(-1,1,1)), axis=1) # 步进1进行输入\n",
    "        # print(future_input[1, -8:-1].reshape(1, -1))\n",
    "\n",
    "    # 将预测结果转换为NumPy数组\n",
    "    future_predictions = np.array(future_predictions).transpose(1,0,2).reshape(-1, next_predict, y_pre_len)\n",
    "\n",
    "    # 创建一个长度为 next_predict+y_pre_len 的数组来存储输出\n",
    "    final_output = np.zeros((future_predictions.shape[0],next_predict+y_pre_len-1))\n",
    "    weights = np.zeros(next_predict+y_pre_len-1)\n",
    "\n",
    "    # 对预测结果进行滑动窗口整合\n",
    "    for i in range(future_predictions.shape[1]):\n",
    "        final_output[:,i:i+5] += future_predictions[:,i]\n",
    "        weights[i:i+5] += 1\n",
    "\n",
    "    # 计算最终输出的平均值\n",
    "    final_output = final_output /weights\n",
    "    future_predictions = final_output.reshape(-1, next_predict + y_pre_len - 1, 1)\n",
    "\n",
    "    future_predictions = np.round(future_predictions)\n",
    "    history_predictions = np.round(history_predictions)\n",
    "\n",
    "    for i in range(future_predictions.shape[1]):\n",
    "        table_save[\"extend_extend_data\"+str(i+1)].loc[category_data.index] = future_predictions[:,i].flatten()\n",
    "\n",
    "    accuracy_cal =  1-np.sum(np.abs(history_predictions - time_series_data[:,-history_predictions.shape[1]:]),axis = 1)/np.sum(time_series_data,axis =1)\n",
    "\n",
    "    select_index = 1\n",
    "    plot_series_data = time_series_data[select_index]\n",
    "    plot_future_prediction = future_predictions[select_index]\n",
    "    plot_history_prediction = history_predictions[select_index]\n",
    "    # 绘制时间序列数据和预测值，使用不同颜色区分\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(np.arange(len(plot_series_data)-len(plot_history_prediction)), plot_series_data[-len(plot_history_prediction):], label='Original Data', color='blue')\n",
    "    # plt.plot(np.arange(window_size + y_pre_len - 1, len(plot_series_data)), plot_history_prediction,\n",
    "    #             label='history prediction Data', color='red')\n",
    "    plt.plot(np.arange(len(plot_series_data) - 1, len(plot_series_data) + next_predict + y_pre_len + plot_history_prediction.shape[0]),\n",
    "                np.insert(np.insert(plot_future_prediction, 0, plot_history_prediction), 0 , plot_series_data[-len(plot_history_prediction)]),\n",
    "                label='Predicted Data', color='green', ls=\"--\")\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"/workspace/save_pic2/\"+str(select_index)+str(fenlei_index)+\".svg\")\n",
    "    plt.show()\n",
    "\n",
    "    # table_save.to_csv(\"/workspace/table_save4/table_save_\"+str(fenlei_index)+\"_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_review = pd.read_csv(\"/workspace/1111.csv\", encoding=\"gb18030\", index_col=0)\n",
    "table = pd.read_csv(\"/workspace/q1_result.csv\", encoding=\"utf-8\", index_col=0)\n",
    "\n",
    "table_save = table.copy()\n",
    "table[\"data_len\"] = np.nan\n",
    "table_data = table[\"data\"]  # 获取data数据\n",
    "for i in range(len(table)):\n",
    "    table[\"data_len\"].iloc[i] = len(eval(table[\"data\"].iloc[i]))\n",
    "for fenlei_index in range(0, 22):\n",
    "    category_data = table[table['fenlei'] == fenlei_index]\n",
    "    if not category_data.empty:\n",
    "        print(fenlei_index, min(category_data[\"data_len\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
